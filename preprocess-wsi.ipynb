{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a79f9ef66bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import math\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.ndimage.morphology as sc_morph\n",
    "import skimage.color as sk_color\n",
    "import skimage.exposure as sk_exposure\n",
    "import skimage.feature as sk_feature\n",
    "import skimage.filters as sk_filters\n",
    "import skimage.future as sk_future\n",
    "import skimage.morphology as sk_morphology\n",
    "import skimage.segmentation as sk_segmentation\n",
    "import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "  gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "  display(Image.fromarray(gray))\n",
    "  return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_grayscale(image):\n",
    "  invert_grayscale = cv2.bitwise_not(image)\n",
    "  display(Image.fromarray(invert_grayscale))\n",
    "  return invert_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_threshold(image,orig):\n",
    "  ret,basic_threshold=cv2.threshold(image,180,255,cv2.THRESH_BINARY)\n",
    "  display(Image.fromarray(basic_threshold))\n",
    "  return basic_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_threshold(image):\n",
    "  ret2,otsu_threshold=cv2.threshold(image,10,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "  display(Image.fromarray(otsu_threshold))\n",
    "  return otsu_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time:\n",
    "  \"\"\"\n",
    "  Class for displaying elapsed time.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.start = datetime.datetime.now()\n",
    "\n",
    "  def elapsed_display(self):\n",
    "    time_elapsed = self.elapsed()\n",
    "    print(\"Time elapsed: \" + str(time_elapsed))\n",
    "\n",
    "  def elapsed(self):\n",
    "    self.end = datetime.datetime.now()\n",
    "    time_elapsed = self.end - self.start\n",
    "    return time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rgb_to_grayscale(np_img, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Convert an RGB NumPy array to a grayscale NumPy array.\n",
    "  Shape (h, w, c) to (h, w).\n",
    "  Args:\n",
    "    np_img: RGB Image as a NumPy array.\n",
    "    output_type: Type of array to return (float or uint8)\n",
    "  Returns:\n",
    "    Grayscale image as NumPy array with shape (h, w).\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  grayscale = np.dot(np_img[..., :3], [0.2125, 0.7154, 0.0721])\n",
    "  if output_type != \"float\":\n",
    "    grayscale = grayscale.astype(\"uint8\")\n",
    "  np_info(grayscale, \"Gray\", t.elapsed())\n",
    "  display(Image.fromarray(grayscale))\n",
    "  return grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_complement(np_img, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Obtain the complement of an image as a NumPy array.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    type: Type of array to return (float or uint8).\n",
    "  Returns:\n",
    "    Complement image as Numpy array.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  if output_type == \"float\":\n",
    "    complement = 1.0 - np_img\n",
    "  else:\n",
    "    complement = 255 - np_img\n",
    "  np_info(complement, \"Complement\", t.elapsed())\n",
    "  display(Image.fromarray(complement))\n",
    "  return complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hysteresis_threshold(np_img, low=60, high=150, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Apply two-level (hysteresis) threshold to an image as a NumPy array, returning a binary image.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    low: Low threshold.\n",
    "    high: High threshold.\n",
    "    output_type: Type of array to return (bool, float, or uint8).\n",
    "  Returns:\n",
    "    NumPy array (bool, float, or uint8) where True, 1.0, and 255 represent a pixel above hysteresis threshold.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  hyst = sk_filters.apply_hysteresis_threshold(np_img, low, high)\n",
    "  if output_type == \"bool\":\n",
    "    pass\n",
    "  elif output_type == \"float\":\n",
    "    hyst = hyst.astype(float)\n",
    "  else:\n",
    "    hyst = (255 * hyst).astype(\"uint8\")\n",
    "  np_info(hyst, \"Hysteresis Threshold\", t.elapsed())\n",
    "  display(Image.fromarray(hyst))\n",
    "  return hyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_otsu_threshold(np_img, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Compute Otsu threshold on image as a NumPy array and return binary image based on pixels above threshold.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    output_type: Type of array to return (bool, float, or uint8).\n",
    "  Returns:\n",
    "    NumPy array (bool, float, or uint8) where True, 1.0, and 255 represent a pixel above Otsu threshold.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  otsu_thresh_value = sk_filters.threshold_otsu(np_img)\n",
    "  otsu = (np_img > otsu_thresh_value)\n",
    "  if output_type == \"bool\":\n",
    "    pass\n",
    "  elif output_type == \"float\":\n",
    "    otsu = otsu.astype(float)\n",
    "  else:\n",
    "    otsu = otsu.astype(\"uint8\") * 255\n",
    "  np_info(otsu, \"Otsu Threshold\", t.elapsed())\n",
    "  display(Image.fromarray(otsu))\n",
    "  return otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_local_otsu_threshold(np_img, disk_size=3, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Compute local Otsu threshold for each pixel and return binary image based on pixels being less than the\n",
    "  local Otsu threshold.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    disk_size: Radius of the disk structuring element used to compute the Otsu threshold for each pixel.\n",
    "    output_type: Type of array to return (bool, float, or uint8).\n",
    "  Returns:\n",
    "    NumPy array (bool, float, or uint8) where local Otsu threshold values have been applied to original image.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  local_otsu = sk_filters.rank.otsu(np_img, sk_morphology.disk(disk_size))\n",
    "  if output_type == \"bool\":\n",
    "    pass\n",
    "  elif output_type == \"float\":\n",
    "    local_otsu = local_otsu.astype(float)\n",
    "  else:\n",
    "    local_otsu = local_otsu.astype(\"uint8\") * 255\n",
    "  np_info(local_otsu, \"Otsu Local Threshold\", t.elapsed())\n",
    "  display(Image.fromarray(local_otsu))\n",
    "  return local_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_entropy(np_img, neighborhood=9, threshold=5, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Filter image based on entropy (complexity).\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    neighborhood: Neighborhood size (defines height and width of 2D array of 1's).\n",
    "    threshold: Threshold value.\n",
    "    output_type: Type of array to return (bool, float, or uint8).\n",
    "  Returns:\n",
    "    NumPy array (bool, float, or uint8) where True, 1.0, and 255 represent a measure of complexity.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  entr = sk_filters.rank.entropy(np_img, np.ones((neighborhood, neighborhood))) > threshold\n",
    "  if output_type == \"bool\":\n",
    "    pass\n",
    "  elif output_type == \"float\":\n",
    "    entr = entr.astype(float)\n",
    "  else:\n",
    "    entr = entr.astype(\"uint8\") * 255\n",
    "  np_info(entr, \"Entropy\", t.elapsed())\n",
    "  display(Image.fromarray(entr))\n",
    "  return entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_canny(np_img, sigma=1, low_threshold=0, high_threshold=25, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Filter image based on Canny algorithm edges.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    sigma: Width (std dev) of Gaussian.\n",
    "    low_threshold: Low hysteresis threshold value.\n",
    "    high_threshold: High hysteresis threshold value.\n",
    "    output_type: Type of array to return (bool, float, or uint8).\n",
    "  Returns:\n",
    "    NumPy array (bool, float, or uint8) representing Canny edge map (binary image).\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  can = sk_feature.canny(np_img, sigma=sigma, low_threshold=low_threshold, high_threshold=high_threshold)\n",
    "  if output_type == \"bool\":\n",
    "    pass\n",
    "  elif output_type == \"float\":\n",
    "    can = can.astype(float)\n",
    "  else:\n",
    "    can = can.astype(\"uint8\") * 255\n",
    "  np_info(can, \"Canny Edges\", t.elapsed())\n",
    "  display(Image.fromarray(can))\n",
    "  return can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_contrast_stretch(np_img, low=40, high=60):\n",
    "  \"\"\"\n",
    "  Filter image (gray or RGB) using contrast stretching to increase contrast in image based on the intensities in\n",
    "  a specified range.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array (gray or RGB).\n",
    "    low: Range low value (0 to 255).\n",
    "    high: Range high value (0 to 255).\n",
    "  Returns:\n",
    "    Image as NumPy array with contrast enhanced.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  low_p, high_p = np.percentile(np_img, (low * 100 / 255, high * 100 / 255))\n",
    "  contrast_stretch = sk_exposure.rescale_intensity(np_img, in_range=(low_p, high_p))\n",
    "  np_info(contrast_stretch, \"Contrast Stretch\", t.elapsed())\n",
    "  display(Image.fromarray(contrast_stretch))\n",
    "  return contrast_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_histogram_equalization(np_img, nbins=256, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Filter image (gray or RGB) using histogram equalization to increase contrast in image.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array (gray or RGB).\n",
    "    nbins: Number of histogram bins.\n",
    "    output_type: Type of array to return (float or uint8).\n",
    "  Returns:\n",
    "     NumPy array (float or uint8) with contrast enhanced by histogram equalization.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  # if uint8 type and nbins is specified, convert to float so that nbins can be a value besides 256\n",
    "  if np_img.dtype == \"uint8\" and nbins != 256:\n",
    "    np_img = np_img / 255\n",
    "  hist_equ = sk_exposure.equalize_hist(np_img, nbins=nbins)\n",
    "  if output_type == \"float\":\n",
    "    pass\n",
    "  else:\n",
    "    hist_equ = (hist_equ * 255).astype(\"uint8\")\n",
    "  np_info(hist_equ, \"Hist Equalization\", t.elapsed())\n",
    "  display(Image.fromarray(hist_equ))\n",
    "  return hist_equ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_adaptive_equalization(np_img, nbins=256, clip_limit=0.01, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Filter image (gray or RGB) using adaptive equalization to increase contrast in image, where contrast in local regions\n",
    "  is enhanced.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array (gray or RGB).\n",
    "    nbins: Number of histogram bins.\n",
    "    clip_limit: Clipping limit where higher value increases contrast.\n",
    "    output_type: Type of array to return (float or uint8).\n",
    "  Returns:\n",
    "     NumPy array (float or uint8) with contrast enhanced by adaptive equalization.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  adapt_equ = sk_exposure.equalize_adapthist(np_img, nbins=nbins, clip_limit=clip_limit)\n",
    "  if output_type == \"float\":\n",
    "    pass\n",
    "  else:\n",
    "    adapt_equ = (adapt_equ * 255).astype(\"uint8\")\n",
    "  np_info(adapt_equ, \"Adapt Equalization\", t.elapsed())\n",
    "  display(Image.fromarray(adapt_equ))\n",
    "  return adapt_equ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_local_equalization(np_img, disk_size=50):\n",
    "  \"\"\"\n",
    "  Filter image (gray) using local equalization, which uses local histograms based on the disk structuring element.\n",
    "  Args:\n",
    "    np_img: Image as a NumPy array.\n",
    "    disk_size: Radius of the disk structuring element used for the local histograms\n",
    "  Returns:\n",
    "    NumPy array with contrast enhanced using local equalization.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  local_equ = sk_filters.rank.equalize(np_img, selem=sk_morphology.disk(disk_size))\n",
    "  np_info(local_equ, \"Local Equalization\", t.elapsed())\n",
    "  display(Image.fromarray(local_equ))\n",
    "  return local_equ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rgb_to_hed(np_img, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Filter RGB channels to HED (Hematoxylin - Eosin - Diaminobenzidine) channels.\n",
    "  Args:\n",
    "    np_img: RGB image as a NumPy array.\n",
    "    output_type: Type of array to return (float or uint8).\n",
    "  Returns:\n",
    "    NumPy array (float or uint8) with HED channels.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  hed = sk_color.rgb2hed(np_img)\n",
    "  if output_type == \"float\":\n",
    "    hed = sk_exposure.rescale_intensity(hed, out_range=(0.0, 1.0))\n",
    "  else:\n",
    "    hed = (sk_exposure.rescale_intensity(hed, out_range=(0, 255))).astype(\"uint8\")\n",
    "\n",
    "  np_info(hed, \"RGB to HED\", t.elapsed())\n",
    "  display(Image.fromarray(hed))\n",
    "  return hed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rgb_to_hsv(np_img, display_np_info=True):\n",
    "  \"\"\"\n",
    "  Filter RGB channels to HSV (Hue, Saturation, Value).\n",
    "  Args:\n",
    "    np_img: RGB image as a NumPy array.\n",
    "    display_np_info: If True, display NumPy array info and filter time.\n",
    "  Returns:\n",
    "    Image as NumPy array in HSV representation.\n",
    "  \"\"\"\n",
    "\n",
    "  if display_np_info:\n",
    "    t = Time()\n",
    "  hsv = sk_color.rgb2hsv(np_img)\n",
    "  if display_np_info:\n",
    "    np_info(hsv, \"RGB to HSV\", t.elapsed())\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(hsv)\n",
    "  return hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hed_to_hematoxylin(np_img, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Obtain Hematoxylin channel from HED NumPy array and rescale it (for example, to 0 to 255 for uint8) for increased\n",
    "  contrast.\n",
    "  Args:\n",
    "    np_img: HED image as a NumPy array.\n",
    "    output_type: Type of array to return (float or uint8).\n",
    "  Returns:\n",
    "    NumPy array for Hematoxylin channel.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  hema = np_img[:, :, 0]\n",
    "  if output_type == \"float\":\n",
    "    hema = sk_exposure.rescale_intensity(hema, out_range=(0.0, 1.0))\n",
    "  else:\n",
    "    hema = (sk_exposure.rescale_intensity(hema, out_range=(0, 255))).astype(\"uint8\")\n",
    "  np_info(hema, \"HED to Hematoxylin\", t.elapsed())\n",
    "  display(Image.fromarray(hema))\n",
    "  return hema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hed_to_eosin(np_img, output_type=\"uint8\"):\n",
    "  \"\"\"\n",
    "  Obtain Eosin channel from HED NumPy array and rescale it (for example, to 0 to 255 for uint8) for increased\n",
    "  contrast.\n",
    "  Args:\n",
    "    np_img: HED image as a NumPy array.\n",
    "    output_type: Type of array to return (float or uint8).\n",
    "  Returns:\n",
    "    NumPy array for Eosin channel.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  eosin = np_img[:, :, 1]\n",
    "  if output_type == \"float\":\n",
    "    eosin = sk_exposure.rescale_intensity(eosin, out_range=(0.0, 1.0))\n",
    "  else:\n",
    "    eosin = (sk_exposure.rescale_intensity(eosin, out_range=(0, 255))).astype(\"uint8\")\n",
    "  np_info(eosin, \"HED to Eosin\", t.elapsed())\n",
    "  display(Image.fromarray(eosin))\n",
    "  return eosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kmeans_segmentation(np_img, compactness=10, n_segments=800):\n",
    "  \"\"\"\n",
    "  Use K-means segmentation (color/space proximity) to segment RGB image where each segment is\n",
    "  colored based on the average color for that segment.\n",
    "  Args:\n",
    "    np_img: Binary image as a NumPy array.\n",
    "    compactness: Color proximity versus space proximity factor.\n",
    "    n_segments: The number of segments.\n",
    "  Returns:\n",
    "    NumPy array (uint8) representing 3-channel RGB image where each segment has been colored based on the average\n",
    "    color for that segment.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  labels = sk_segmentation.slic(np_img, compactness=compactness, n_segments=n_segments)\n",
    "  result = sk_color.label2rgb(labels, np_img, kind='avg')\n",
    "  np_info(result, \"K-Means Segmentation\", t.elapsed())\n",
    "  display(Image.fromarray(result))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rag_threshold(np_img, compactness=10, n_segments=800, threshold=9):\n",
    "  \"\"\"\n",
    "  Use K-means segmentation to segment RGB image, build region adjacency graph based on the segments, combine\n",
    "  similar regions based on threshold value, and then output these resulting region segments.\n",
    "  Args:\n",
    "    np_img: Binary image as a NumPy array.\n",
    "    compactness: Color proximity versus space proximity factor.\n",
    "    n_segments: The number of segments.\n",
    "    threshold: Threshold value for combining regions.\n",
    "  Returns:\n",
    "    NumPy array (uint8) representing 3-channel RGB image where each segment has been colored based on the average\n",
    "    color for that segment (and similar segments have been combined).\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  labels = sk_segmentation.slic(np_img, compactness=compactness, n_segments=n_segments)\n",
    "  g = sk_future.graph.rag_mean_color(np_img, labels)\n",
    "  labels2 = sk_future.graph.cut_threshold(labels, g, threshold)\n",
    "  result = sk_color.label2rgb(labels2, np_img, kind='avg')\n",
    "  np_info(result, \"RAG Threshold\", t.elapsed())\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_threshold(np_img, threshold, output_type=\"bool\"):\n",
    "  \"\"\"\n",
    "  Return mask where a pixel has a value if it exceeds the threshold value.\n",
    "  Args:\n",
    "    np_img: Binary image as a NumPy array.\n",
    "    threshold: The threshold value to exceed.\n",
    "    output_type: Type of array to return (bool, float, or uint8).\n",
    "  Returns:\n",
    "    NumPy array representing a mask where a pixel has a value (T, 1.0, or 255) if the corresponding input array\n",
    "    pixel exceeds the threshold value.\n",
    "  \"\"\"\n",
    "  t = Time()\n",
    "  result = (np_img > threshold)\n",
    "  if output_type == \"bool\":\n",
    "    pass\n",
    "  elif output_type == \"float\":\n",
    "    result = result.astype(float)\n",
    "  else:\n",
    "    result = result.astype(\"uint8\") * 255\n",
    "  np_info(result, \"Threshold\", t.elapsed())\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
